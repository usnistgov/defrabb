---
title: "defrabb run analysis summary"
date: '`r Sys.Date()`'
format:
  html:
    theme: flatly
    page-layout: full
    toc: true
    self-contained: true
editor: source
code-fold: true
execute:
  warning: false
params:
  yaml_path: "na"
---



```{r setup}
#| include=FALSE,
#| echo=TRUE
library(tidyverse)
library(DT)
library(jsonlite)
library(yaml)
library(sessioninfo)
run_params <- read_yaml(params$yaml_path) 
```


## defrabb run results
<!-- ::: {.panel-tabset} -->

## Utils/ Functions 
```{r utils}
get_var_allele_start <- function(rtg_stats_file){
  stat_file_lines <- read_lines(rtg_stats_file)
  grep("Variant Allele Lengths", stat_file_lines)
}


get_rtg_metrics <- function(rtg_stats_file) {
  n_stat_rows <- get_var_allele_start(rtg_stats_file) - 1
  read_delim(
    rtg_stats_file,
    n_max = n_stat_rows,
    skip = 1,
    delim = ":",
    trim_ws = TRUE,
    col_names = c("metric", "value"),
    col_types = "cc"
  )
}

get_rtg_var_lengths <- function(rtg_stats_file) {
  var_row_start <- get_var_allele_start(rtg_stats_file)
  read_tsv(rtg_stats_file, skip = var_row_start, col_types = "cddddd") %>%
    rename(var_length = length)
}
```

## Assembly-Based Variant Calls and Regions

### Variant Calls
Summary statistics calculated using rtg-tools vcfstats.

From https://cdn.jsdelivr.net/gh/RealTimeGenomics/rtg-tools@master/installer/resources/tools/RTGOperationsManual.pdf

- SNPs: can include variants with length greater than 1 bp but with only a mismatch in the first or last base.  
- MNPs: Cases where multiple bases change, but the lengths of the two alleles do not are considered to be MNPs
- Insersions/Deletions: Cases where there is pure addition or removal of bases are classified as Insertions or Deletions respectively
- Indels: there there is a length change between the REF and ALT, but it is not pure




```{r asmvartbl}
asm_var_rtg_stat_files <- run_params$inputs$asm_var_rtg %>% 
  set_names(str_extract(., "(?<=asm_varcalls/).*(?=/)"))

asm_var_rtg_stat_df <- asm_var_rtg_stat_files %>%
  map_dfr(get_rtg_metrics, .id = "asm_varcalls") %>%
  pivot_wider(
    id_cols = asm_varcalls,
    names_from = metric,
    values_from = value,
    values_fill = NA
  ) %>%
  separate(col = asm_varcalls,
           into = c("ref", "asm_varcall"),
           sep = "_")
DT::datatable(asm_var_rtg_stat_df)
```

```{r asmvarfigins}
var_lengths_df <- asm_var_rtg_stat_files %>% 
  map_dfr(get_rtg_var_lengths, .id = "asm_varcalls") %>%
  separate(col = asm_varcalls, into = c("ref","asm_varcall"), sep = "_")

var_len_lvls <- var_lengths_df$var_length %>% unique()
var_lengths_df <- var_lengths_df %>% mutate(var_length = factor(var_length, levels = var_len_lvls))

ggplot(var_lengths_df) + 
  geom_col(aes(x = var_length, y = Insert)) + 
  facet_grid(ref ~ ., scales = "free_x") + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = -45, hjust = 0)) + 
  scale_x_discrete(breaks = var_len_lvls[seq(from = 1, to = length(var_len_lvls), by = 10)]) +
  scale_y_log10()
```


```{r asmvarinsdel}
ggplot(var_lengths_df) + 
  geom_col(aes(x = var_length, y = Delete)) + 
  facet_grid(ref ~ ., scales = "free_x") + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = -45, hjust = 0)) + 
  scale_x_discrete(breaks = var_len_lvls[seq(from = 1, to = length(var_len_lvls), by = 10)]) +
  scale_y_log10()
```


## Benchmark Variants Summary

```{r benchvardf}
bench_var_rtg_stat_files <- run_params$inputs$bench_var_rtg %>%
  set_names(str_extract(., "(?<=benchmarksets/).*(?=/)"))

bench_var_metrics_df <- bench_var_rtg_stat_files %>% 
  map_dfr(get_rtg_metrics, .id = "benchmarkset") %>% 
  pivot_wider(id_cols = benchmarkset, names_from = metric, values_from = value, values_fill = NA) %>% 
  separate(col = benchmarkset, into = c("ref","asm_varcall", "bench_type"), sep = "_")
```

### Summary Statistics
Summary statistics calculated using rtg-tools vcfstats.

```{r benchvartbl}
DT::datatable(bench_var_metrics_df)
```




#### SV length characterizations

```{r benchvarfigins}
var_lengths_df <- bench_var_rtg_stat_files %>% 
  map_dfr(get_rtg_var_lengths, .id = "benchmarkset") %>%
  separate(col = benchmarkset, into = c("ref","asm_varcall", "bench_type"), sep = "_")

var_len_lvls <- var_lengths_df$var_length %>% unique()
var_lengths_df <- var_lengths_df %>% mutate(var_length = factor(var_length, levels = var_len_lvls))

ggplot(var_lengths_df) + 
  geom_col(aes(x = var_length, y = Insert)) + 
  facet_grid(ref ~ bench_type, scales = "free_x") + 
  theme_bw() + 
  theme(axis.text.x = element_text(angle = -45, hjust = 0)) + 
  scale_x_discrete(breaks = var_len_lvls[seq(from = 1, to = length(var_len_lvls), by = 10)]) +
  scale_y_log10()

## TODO add bench var deletion figure
```


## Benchmark Regions Summary
```{r exclusiontbl}
exclusion_stats_files <- run_params$inputs$exclusion_summary %>%
  set_names(str_remove(., ".*-excluded/"))

exclusion_stats_df <- exclusion_stats_files %>%
  map_dfr(read_tsv, show_col_types = FALSE, .id = "benchmarkset") %>%
  mutate(benchmarkset = str_remove(benchmarkset, ".exclusion_stats.txt")) %>%
  separate(
    benchmarkset,
    sep = "_",
    into = c("refid", "asm_id", "bench_type", "varcall"),
    extra = "merge"
  ) %>%
  mutate(
    exclusion = str_remove(exclusion, ".*dipcall-z2k_"),
    exclusion = str_remove(exclusion, "resources/exclusions/.*/"),
    exclusion = str_remove(exclusion, "_.*bed")
  ) %>%
  unite(ref_bench, refid, bench_type)

initial_stats_df <- exclusion_stats_df %>% 
  filter(exclusion == "initial") %>% 
  select(-exclusion, -exclusion_length) %>% 
  rename(initial_length = resulting_length)

exclusion_stats_df <- exclusion_stats_df %>% 
  left_join(initial_stats_df) %>% 
  mutate(pct_of_initial = resulting_length/initial_length) %>% 
  select(-initial_length)

DT::datatable(
  exclusion_stats_df,
  rownames = FALSE,
  extensions = 'RowGroup',
  options = list(rowGroup = list(dataSrc = 0)),
  selection = 'none'
) %>% 
  DT::formatRound(columns = c("exclusion_length", "resulting_length"), digits = 0) %>% 
  DT::formatPercentage(columns = c("pct_of_initial"), digits = 1)
```

TODO

- modify table for comparisons, separate tables by benchmark set?
- calculate coverage based on non-gap ref bases

### Summary By Chromosome

```{r benchcovtbl}
bench_genomecov_files <-
  run_params$inputs$bench_cov %>%
  set_names(str_extract(., "(?<=excluded/).*(?=.benchmark_bed)"))

chroms <- c(1:22, "X","Y")
chroms <- c(chroms, paste0("chr", chroms))

bench_genomecov_df <- bench_genomecov_files %>%
  map_dfr(read_tsv, show_col_types = FALSE, .id = "benchmarkset") %>%
  separate(
    benchmarkset,
    sep = "_",
    into = c("refid", "asm_id", "bench_type", "varcall"),
    extra = "merge"
  ) %>% 
  filter(chrom %in% chroms) %>% 
  mutate(chrom = factor(chrom, levels = chroms))

ggplot(bench_genomecov_df) +
  geom_col(
    aes(x = chrom, y = total_ivl_bp, fill = bench_type),
    position = "dodge",
    color = "grey20"
  ) +
  facet_wrap( ~ paste(refid, asm_id, varcall),
              scales = "free_x",
              ncol = 1) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "Chromosome", y = "Total Region Size (bp)", fill = "Benchmarkset Type")
```


## Evaluation Results
### Happy Combined Summary Tables

```{r evalsmvartbl}
happy_summary_files <- run_params$inputs$happy_summary %>%
      set_names(str_extract(., "(?<=happy/).*(?=/)"))

happy_summary_df <- happy_summary_files %>%
    map_dfr(read_csv, show_col_types = FALSE, .id = "evaluation") %>%
    filter(Filter == "PASS") %>% 
  ## Assumes evaluation naming convention used in analysis tables
  mutate(
    ref = str_remove(evaluation, "_.*"),
    truth = str_extract(evaluation, "(?<=T~).*(?=_Q)"),
    query = str_extract(evaluation, "(?<=Q~)[^_]*(?=_)"),
    target_regions = str_extract(evaluation, "(?<=TR~)[^_]*(?=_)")
  ) %>% 
  select(ref, truth, query, target_regions, c(2, 4:15))

DT::datatable(happy_summary_df)
```

Add figures for extended csv, see https://gitlab.nist.gov/gitlab/nolson/giab-nrg-variant-calling/-/blob/master/scratch/varcalls_repeats.qmd?ref_type=heads for example code

### Truvari Combined Summary Table

Truth and evaluation ids are based on evaluation id provided in eval_id defined in analysis table and not based on how truvari was run. 
Will want to modify so values are based on truvari command to accurately reflect how truvari was run.

```{r evalstvartbl}
truvari_summary_files <- run_params$inputs$truvari_summary %>%
    set_names(str_extract(., "(?<=truvari/).*(?=/)"))
truvari_summary_df <- truvari_summary_files %>%
    map(jsonlite::fromJSON,
        simplifyVector = FALSE,
        simplifyDataFrame = FALSE,
        simplifyMatrix = FALSE
    ) %>%
    # Remove 'weighted' and 'gt_matrix' keys from each item  
    map(~{.x$weighted <- NULL; .x$gt_matrix <- NULL; .x}) %>%  
    # better handling nulls in list - mostly for test data set
    map_depth(., 2, ~ifelse(is.null(.x), NA, .x)) %>% 
    map_dfr(as_data_frame, .id = "evaluation") %>% 
    ## Assumes evaluation naming convention used in analysis tables
  mutate(
    ref = str_remove(evaluation, "_.*"),
    truth = str_extract(evaluation, "(?<=T~).*(?=_Q)"),
    query = str_extract(evaluation, "(?<=Q~)[^_]*(?=_)"),
    target_regions = str_extract(evaluation, "(?<=TR~)[^_]*(?=_)")
  ) %>% 
  select(ref, truth, query, target_regions, c(2:16))

DT::datatable(truvari_summary_df, rownames = FALSE) %>%
    formatRound(c("precision", "recall", "f1", "gt_concordance"), 5) 

```

The following sections (in addition to the header) provide the __WHO__ and __WHERE__ for the analyses was performed. 

<!-- ::: -->

## System Information
```{r plat}
sessioninfo::platform_info()
```


### Package Versions
```{r pkgs}
sessioninfo::package_info() %>% 
    filter(attached = TRUE) %>% 
    select(package, loadedversion, date, source) %>%
    knitr::kable(booktabs = TRUE, row.names = FALSE)
```
